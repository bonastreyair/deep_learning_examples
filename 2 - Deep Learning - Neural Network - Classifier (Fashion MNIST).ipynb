{"cells":[{"cell_type":"markdown","metadata":{"id":"jqVqT_Cxh4Ho","colab_type":"text"},"source":["# Introduction to Neural Networks\n","In this notebook you will learn how to create and use a neural network to classify articles of clothing. To achieve this, we will use a sub module of TensorFlow called *keras*.\n","\n","*This guide is based on the following TensorFlow documentation.*\n","\n","https://www.tensorflow.org/tutorials/keras/classification\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZFQqW9r-ikJb","colab_type":"text"},"source":["## Keras\n","Before we dive in and start discussing neural networks, I'd like to give a breif introduction to keras.\n","\n","From the keras official documentation (https://keras.io/) keras is described as follows.\n","\n","\"Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. \n","\n","Use Keras if you need a deep learning library that:\n","\n","- Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n","- Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n","- Runs seamlessly on CPU and GPU.\"\n","\n","Keras is a very powerful module that allows us to avoid having to build neural networks from scratch. It also hides a lot of mathematical complexity (that otherwise we would have to implement) inside of helpful packages, modules and methods.\n","\n","In this guide we will use keras to quickly develop neural networks.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Hivk879ZQhxU","colab_type":"text"},"source":["## What is a Neural Network\n","So, what are these magical things that have been beating chess grandmasters, driving cars, detecting cancer cells and winning video games? \n","\n","A deep neural network is a layered representation of data. The term \"deep\" refers to the presence of multiple layers. Recall that in our core learning algorithms (like linear regression) data was not transformed or modified within the model, it simply existed in one layer. We passed some features to our model, some math was done, an answer was returned. The data was not changed or transformed throughout this process. A neural network processes our data differently. It attempts to represent our data in different ways and in different dimensions by applying specific operations to transform our data at each layer. Another way to express this is that at each layer our data is transformed in order to learn more about it. By performing these transformations, the model can better understand our data and therefore provide a better prediction. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"GOqUCZ2klTAq","colab_type":"text"},"source":["## How it Works\n","Before going into too much detail I will provide a very surface level explination of how neural networks work on a mathematical level. All the terms and concepts I discuss will be defined and explained in more detail below.\n","\n","On a lower level neural networks are simply a combination of elementry math operations and some more advanced linear algebra. Each neural network consists of a sequence of layers in which data passes through. These layers are made up on neurons and the neurons of one layer are connected to the next (see below). These connections are defined by what we call a weight (some numeric value). Each layer also has something called a bias, this is simply an extra neuron that has no connections and holds a single numeric value. Data starts at the input layer and is trasnformed as it passes through subsequent layers. The data at each subsequent neuron is defined as the following.\n","\n","> $Y =(\\sum_{i=0}^n w_i x_i) + b$\n","\n","> $w$ stands for the weight of each connection to the neuron\n","\n","> $x$ stands for the value of the connected neuron from the previous value\n","\n","> $b$ stands for the bias at each layer, this is a constant\n","\n","> $n$ is the number of connections\n","\n","> $Y$ is the output of the current neuron\n","\n","> $\\sum$ stands for sum\n","\n","The equation you just read is called a weighed sum. We will take this weighted sum at each and every neuron as we pass information through the network. Then we will add what's called a bias to this sum. The bias allows us to shift the network up or down by a constant value. It is like the y-intercept of a line.\n","\n","But that equation is the not complete one! We forgot a crucial part, **the activation function**. This is a function that we apply to the equation seen above to add complexity and dimensionality to our network. Our new equation with the addition of an activation function $F(x)$ is seen below.\n","\n","> $Y =F((\\sum_{i=0}^n w_i x_i) + b)$\n","\n","Our network will start with predefined activation functions (they may be different at each layer) but random weights and biases. As we train the network by feeding it data it will learn the correct weights and biases and adjust the network accordingly using a technqiue called **backpropagation** (explained below). Once the correct weights and biases have been learned our network will hopefully be able to give us meaningful predictions. We get these predictions by observing the values at our final layer, the output layer. \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"o-oMh18_j5kl","colab_type":"text"},"source":["## Breaking Down The Neural Network!\n","\n","Before we dive into any code lets break down how a neural network works and what it does.\n","\n","![alt text](http://www.extremetech.com/wp-content/uploads/2015/07/NeuralNetwork.png)\n","*Figure 1*\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-9hd-R1ulSdp","colab_type":"text"},"source":["### Data\n","The type of data a neural network processes varies drastically based on the problem being solved. When we build a neural network, we define what shape and kind of data it can accept. It may sometimes be neccessary to modify our dataset so that it can be passed to our neural network. \n","\n","Some common types of data a neural network uses are listed below.\n","- Vector Data (2D)\n","- Timeseries or Sequence (3D)\n","- Image Data (4D)\n","- Video Data (5D)\n","\n","There are of course many different types or data, but these are the main categories.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Xyxxs7oMlWtz","colab_type":"text"},"source":["### Layers\n","As we mentioned earlier each neural network consists of multiple layers. At each layer a different transformation of data occurs. Our initial input data is fed through the layers and eventually arrives at the output layer where we will obtain the result.\n","#### Input Layer\n","The input layer is the layer that our initial data is passed to. It is the first layer in our neural network.\n","#### Output Layer\n","The output layer is the layer that we will retrive our results from. Once the data has passed through all other layers it will arrive here.\n","#### Hidden Layer(s)\n","All the other layers in our neural network are called \"hidden layers\". This is because they are hidden to us, we cannot observe them. Most neural networks consist of at least one hidden layer but can have an unlimited amount. Typically, the more complex the model the more hidden layers.\n","#### Neurons\n","Each layer is made up of what are called neurons. Neurons have a few different properties that we will discuss later. The important aspect to understand now is that each neuron is responsible for generating/holding/passing ONE numeric value. \n","\n","This means that in the case of our input layer it will have as many neurons as we have input information. For example, say we want to pass an image that is 28x28 pixels, thats 784 pixels. We would need 784 neurons in our input layer to capture each of these pixels. \n","\n","This also means that our output layer will have as many neurons as we have output information. The output is a little more complicated to understand so I'll refrain from an example right now but hopefully you're getting the idea.\n","\n","But what about our hidden layers? Well these have as many neurons as we decide. We'll discuss how we can pick these values later but understand a hidden layer can have any number of neurons.\n","####Connected Layers\n","So how are all these layers connected? Well the neurons in one layer will be connected to neurons in the subsequent layer. However, the neurons can be connected in a variety of different ways. \n","\n","Take for example *Figure 1* (look above). Each neuron in one layer is connected to every neuron in the next layer. This is called a **dense** layer. There are many other ways of connecting layers but well discuss those as we see them. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"a_bM6nQ-PZBY","colab_type":"text"},"source":["### Weights\n","Weights are associated with each connection in our neural network. Every pair of connected nodes will have one weight that denotes the strength of the connection between them. These are vital to the inner workings of a neural network and will be tweaked as the neural network is trained. The model will try to determine what these weights should be to achieve the best result. Weights start out at a constant or random value and will change as the network sees training data."]},{"cell_type":"markdown","metadata":{"id":"XwYq9doXeIl-","colab_type":"text"},"source":["### Biases\n","Biases are another important part of neural networks and will also be tweaked as the model is trained. A bias is simply a constant value associated with each layer. It can be thought of as an extra neuron that has no connections. The purpose of a bias is to shift an entire activation function by a constant value. This allows a lot more flexibllity when it comes to choosing an activation and training the network. There is one bias for each layer."]},{"cell_type":"markdown","metadata":{"id":"F92rhvd6PcRI","colab_type":"text"},"source":["### Activation Function\n","Activation functions are simply a function that is applied to the weighed sum of a neuron. They can be anything we want but are typically higher order/degree functions that aim to add a higher dimension to our data. We would want to do this to introduce more comolexity to our model. By transforming our data to a higher dimension, we can typically make better, more complex predictions.\n","\n","A list of some common activation functions and their graphs can be seen below.\n","\n","- Relu (Rectified Linear Unit)\n","\n","![alt text](https://yashuseth.files.wordpress.com/2018/02/relu-function.png?w=309&h=274)\n","- Tanh (Hyperbolic Tangent)\n","\n","![alt text](http://mathworld.wolfram.com/images/interactive/TanhReal.gif)\n","- Sigmoid \n","\n","![alt text](https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Q2xNjpctlBUM","colab_type":"text"},"source":["### Backpropagation\n","Backpropagation is the fundemental algorithm behind training neural networks. It is what changes the weights and biases of our network. To fully explain this process, we need to start by discussing something called a cost/loss function.\n","\n","#### Loss/Cost Function\n","As we now know our neural network feeds information through the layers until it eventually reaches an output layer. This layer contains the results that we look at to determine the prediciton from our network. In the training phase it is likely that our network will make many mistakes and poor predicitions. In fact, at the start of training our network doesn't know anything (it has random weights and biases)! \n","\n","We need some way of evaluating if the network is doing well and how well it is doing. For our training data we have the features (input) and the labels (expected output), because of this we can compare the output from our network to the expected output. Based on the difference between these values we can determine if our network has done a good job or poor job. If the network has done a good job, we'll make minor changes to the weights and biases. If it has done a poor job our changes may be more drastic.\n","\n","So, this is where the cost/loss function comes in. This function is responsible for determining how well the network did. We pass it the output and the expected output, and it returns to us some value representing the cost/loss of the network. This effectively makes the networks job to optimize this cost function, trying to make it as low as possible. \n","\n","Some common loss/cost functions include.\n","- Mean Squared Error\n","- Mean Absolute Error\n","- Hinge Loss\n","\n","#### Gradient Descent\n","Gradient descent and backpropagation are closely related. Gradient descent is the algorithm used to find the optimal paramaters (weights and biases) for our network, while backpropagation is the process of calculating the gradient that is used in the gradient descent step. \n","\n","Gradient descent requires some pretty advanced calculus and linear algebra to understand so we'll stay away from that for now. Let's just read the formal definition for now.\n","\n","\"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.\" (https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html)\n","\n","And that's all we really need to know for now. I'll direct you to the video for a more in depth explination.\n","\n","![alt text](https://cdn-images-1.medium.com/max/1000/1*iU1QCnSTKrDjIPjSAENLuQ.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0KiTMDCKlBI7","colab_type":"text"},"source":["### Optimizer\n","You may sometimes see the term optimizer or optimization function. This is simply the function that implements the backpropagation algorithm described above. Here's a list of a few common ones.\n","- Gradient Descent\n","- Stochastic Gradient Descent\n","- Mini-Batch Gradient Descent\n","- Momentum\n","- Nesterov Accelerated Gradient\n","- Adam\n","\n","*This article explains them quite well is where I've pulled this list from.* (https://medium.com/@sdoshi579/optimizers-for-training-neural-network-59450d71caf6)\n","\n","https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"]},{"cell_type":"markdown","metadata":{"id":"Kc5hFCLSiDNr","colab_type":"text"},"source":["# Creating a Neural Network\n","Okay now you have reached the exciting part of this tutorial! No more math and complex explinations. Time to get hands on and train a very basic neural network.\n","\n","*As stated earlier this guide is based off of the following TensorFlow tutorial.*\n","https://www.tensorflow.org/tutorials/keras/classification\n"]},{"cell_type":"markdown","metadata":{"id":"3io6gbUrjOQY","colab_type":"text"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"y8t_EdO8jEHz","colab_type":"code","colab":{}},"source":["# TensorFlow and tf.keras\n","import tensorflow as tf\n","\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p_iFN10li6V1","colab_type":"text"},"source":["### Dataset\n","For this tutorial we will use the MNIST Fashion Dataset. This is a dataset that is included in keras.\n","\n","This dataset includes 60,000 images for training and 10,000 images for validation/testing."]},{"cell_type":"code","metadata":{"id":"eQmVmgOxjCOV","colab_type":"code","colab":{}},"source":["fashion_mnist = tf.keras.datasets.fashion_mnist  # load dataset\n","\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()  # split into tetsing and training"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 2s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n8192/5148 [===============================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 0s 0us/step\n"}]},{"cell_type":"markdown","metadata":{"id":"AcIall2njfn1","colab_type":"text"},"source":["Let's have a look at this data to see what we are working with."]},{"cell_type":"code","metadata":{"id":"WhLXRxOdjisI","colab_type":"code","outputId":"3bc3a5f0-a32d-4043-f814-1af640b77a93","executionInfo":{"status":"ok","timestamp":1590922944628,"user_tz":-120,"elapsed":2347,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_images.shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":"(60000, 28, 28)"},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"D2npdFHwjsLS","colab_type":"text"},"source":["So we've got 60,000 images that are made up of 28x28 pixels (784 in total)."]},{"cell_type":"code","metadata":{"id":"m280zyPqj3ws","colab_type":"code","outputId":"7ec65b5c-cfc7-41db-ac4a-8508458740fd","executionInfo":{"status":"ok","timestamp":1590922945078,"user_tz":-120,"elapsed":2784,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_images[0,23,23]  # let's have a look at one pixel"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":"194"},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"GUciblEwkBe4","colab_type":"text"},"source":["Our pixel values are between 0 and 255, 0 being black and 255 being white. This means we have a grayscale image as there are no color channels."]},{"cell_type":"code","metadata":{"id":"Rn78KO7fkQPJ","colab_type":"code","outputId":"3839a664-1eb8-4e26-9a8b-1d08a1202fcb","executionInfo":{"status":"ok","timestamp":1590922945079,"user_tz":-120,"elapsed":2773,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_labels[:10]  # let's have a look at the first 10 training labels"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint8)"},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"r90qZKsnkaW7","colab_type":"text"},"source":["Our labels are integers ranging from 0 - 9. Each integer represents a specific article of clothing. We'll create an array of label names to indicate which is which."]},{"cell_type":"code","metadata":{"id":"pBiICD2tkne8","colab_type":"code","colab":{}},"source":["class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4rv06eD8krMR","colab_type":"text"},"source":["Fianlly let's look at what some of these images look like!"]},{"cell_type":"code","metadata":{"id":"Nfc8LV4Pkq0X","colab_type":"code","outputId":"b59d37ef-2b36-43e8-dad8-a0f6265926f3","executionInfo":{"status":"ok","timestamp":1590922945080,"user_tz":-120,"elapsed":2752,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["plt.figure()\n","plt.imshow(train_images[1])\n","plt.colorbar()\n","plt.grid(False)\n","plt.show()"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 305.2645 248.518125\" width=\"305.2645pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 305.2645 248.518125 \nL 305.2645 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p6ea6a518ba)\">\n    <image height=\"218\" id=\"imageb3a614eb4b\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m1f90e001d6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m1f90e001d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m1f90e001d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m1f90e001d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m1f90e001d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m1f90e001d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m1f90e001d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"ma2acd2f7fa\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2acd2f7fa\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2acd2f7fa\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2acd2f7fa\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2acd2f7fa\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2acd2f7fa\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma2acd2f7fa\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p55cf1eac7e)\" d=\"M 261.105 224.64 \nL 261.105 223.790625 \nL 261.105 8.049375 \nL 261.105 7.2 \nL 271.977 7.2 \nL 271.977 8.049375 \nL 271.977 223.790625 \nL 271.977 224.64 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\n   </g>\n   <image height=\"217\" id=\"image23274e2ef2\" transform=\"scale(1 -1)translate(0 -217)\" width=\"11\" x=\"261\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAAsAAADZCAYAAAD2WsoCAAAABHNCSVQICAgIfAhkiAAAAUhJREFUaIHdmsENAjEMBGM7R2XUQP+NQGjB8xjJd7yt1e6sQ9Bx8c7PWc3Pjozu7Norsj/MlKuIDaAcCTwj5aUpB6LBGtSGh3AWaWg2RHQWjcNstGdNGqJn7VidmtFgf9YMeDQbKKC3SIccWI8GVAbDcJ+J8h1piHUjG5qyRsPcDUvZ5HxDdDO2boqyR6M/iy96YgPdg5qN59f9eHQ3DOjVvaJ/vsegux8N4JgHBJ69UkTOM2iAn0huKV7AEcrgORmkwWzMQJdiQIuG5zmTDHs2loWu8gdseAFFGmB4azS8gJ4NRkP0bJWymTIYLrFui8YVX0kZ0rACFlG+ktAgDZa3dcQGrBvZGNEg4sxoMBtWQFTKSwyo7YZ2rK4FaMCA1j3Ilp99FXgB27NUuS+89ov83YCUiymD4SLDSPkK8LoO80zeOUnwkOoPXoiBaF8nrs8AAAAASUVORK5CYII=\" y=\"-7\"/>\n   <g id=\"matplotlib.axis_3\"/>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <defs>\n       <path d=\"M 0 0 \nL 3.5 0 \n\" id=\"mda9a1d896a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#mda9a1d896a\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0 -->\n      <g transform=\"translate(278.977 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#mda9a1d896a\" y=\"182.004706\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 50 -->\n      <g transform=\"translate(278.977 185.803925)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#mda9a1d896a\" y=\"139.369412\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 100 -->\n      <g transform=\"translate(278.977 143.168631)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#mda9a1d896a\" y=\"96.734118\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 150 -->\n      <g transform=\"translate(278.977 100.533336)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#mda9a1d896a\" y=\"54.098824\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 200 -->\n      <g transform=\"translate(278.977 57.898042)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#mda9a1d896a\" y=\"11.463529\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 250 -->\n      <g transform=\"translate(278.977 15.262748)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 261.105 224.64 \nL 261.105 223.790625 \nL 261.105 8.049375 \nL 261.105 7.2 \nL 271.977 7.2 \nL 271.977 8.049375 \nL 271.977 223.790625 \nL 271.977 224.64 \nz\n\" style=\"fill:none;stroke:#000000;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p6ea6a518ba\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n  <clipPath id=\"p55cf1eac7e\">\n   <rect height=\"217.44\" width=\"10.872\" x=\"261.105\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"n_DC1b0grL1N","colab_type":"text"},"source":["## Data Preprocessing\n","The last step before creating our model is to *preprocess* our data. This simply means applying some prior transformations to our data before feeding it the model. In this case we will simply scale all our greyscale pixel values (0-255) to be between 0 and 1. We can do this by dividing each value in the training and testing sets by 255.0. We do this because smaller values will make it easier for the model to process our values. \n","\n"]},{"cell_type":"code","metadata":{"id":"wHde8MYW0OQo","colab_type":"code","colab":{}},"source":["train_images = train_images / 255.0\n","test_images = test_images / 255.0"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dHOX6GqR0QuD","colab_type":"text"},"source":["## Building the Model\n","Now it's time to build the model! We are going to use a keras *sequential* model with three different layers. This model represents a feed-forward neural network (one that passes values from left to right). We'll break down each layer and its architecture below."]},{"cell_type":"code","metadata":{"id":"XDxodHMv0xgG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"de4fdc32-5875-46f9-9cd4-520a048e677e","executionInfo":{"status":"ok","timestamp":1590922945276,"user_tz":-120,"elapsed":2921,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense\n","\n","model = Sequential()\n","\n","model.add(Flatten(input_shape=(28, 28), name=\"flatten_1\"))\n","model.add(Dense(128, activation='relu', name=\"dense_1\"))\n","model.add(Dense(10, activation='softmax', name=\"dense_output\"))\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten_1 (Flatten)          (None, 784)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               100480    \n_________________________________________________________________\ndense_output (Dense)         (None, 10)                1290      \n=================================================================\nTotal params: 101,770\nTrainable params: 101,770\nNon-trainable params: 0\n_________________________________________________________________\n"}]},{"cell_type":"markdown","metadata":{"id":"c-bL-I5w0414","colab_type":"text"},"source":["**Layer 1:** This is our input layer and it will conist of 784 neurons. We use the flatten layer with an input shape of (28, 28) to denote that our input should come in in that shape. The flatten means that our layer will reshape the shape (28, 28) array into a vector of 784 neurons so that each pixel will be associated with one neuron.\n","\n","**Layer 2:** This is our first and only hidden layer. The *dense* denotes that this layer will be fully connected and each neuron from the previous layer connects to each neuron of this layer. It has 128 neurons and uses the rectify linear unit activation function.\n","\n","**Layer 3:** This is our output later and is also a dense layer. It has 10 neurons that we will look at to determine our models output. Each neuron represnts the probabillity of a given image being one of the 10 different classes. The activation function *softmax* is used on this layer to calculate a probabillity distribution for each class. This means the value of any neuron in this layer will be between 0 and 1, where 1 represents a high probabillity of the image being that class.\n","\n","### Compile the Model\n","The last step in building the model is to define the loss function, optimizer and metrics we would like to track. I won't go into detail about why we chose each of these right now."]},{"cell_type":"markdown","metadata":{"id":"7YYW5V_53OXV","colab_type":"text"},"source":["## Training the Model\n","Now it's finally time to train the model. Since we've already done all the work on our data this step is as easy as calling a single method."]},{"cell_type":"code","metadata":{"id":"XmAtc4uI3_C7","colab_type":"code","outputId":"5a73330b-28ca-4268-a118-2b4b1612eabc","executionInfo":{"status":"ok","timestamp":1590922981845,"user_tz":-120,"elapsed":39478,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["epochs = 10\n","validation_split = 0.10\n","\n","history = model.fit(train_images, train_labels, \n","                    epochs=epochs, \n","                    validation_split=validation_split)  # we pass the data, labels and epochs and watch the magic!"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.5073 - accuracy: 0.8218 - val_loss: 0.3877 - val_accuracy: 0.8565\nEpoch 2/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.3791 - accuracy: 0.8642 - val_loss: 0.3604 - val_accuracy: 0.8712\nEpoch 3/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.3434 - accuracy: 0.8745 - val_loss: 0.3435 - val_accuracy: 0.8785\nEpoch 4/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.3160 - accuracy: 0.8832 - val_loss: 0.3464 - val_accuracy: 0.8707\nEpoch 5/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.2975 - accuracy: 0.8897 - val_loss: 0.3349 - val_accuracy: 0.8788\nEpoch 6/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.2838 - accuracy: 0.8954 - val_loss: 0.3307 - val_accuracy: 0.8802\nEpoch 7/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.2704 - accuracy: 0.8991 - val_loss: 0.3295 - val_accuracy: 0.8843\nEpoch 8/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.2604 - accuracy: 0.9032 - val_loss: 0.3377 - val_accuracy: 0.8833\nEpoch 9/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.2499 - accuracy: 0.9068 - val_loss: 0.3511 - val_accuracy: 0.8792\nEpoch 10/10\n1688/1688 [==============================] - 2s 1ms/step - loss: 0.2388 - accuracy: 0.9098 - val_loss: 0.3308 - val_accuracy: 0.8858\n"}]},{"cell_type":"markdown","metadata":{"id":"y6SRtNcF4K1O","colab_type":"text"},"source":["## Evaluating the Model\n","Now it's time to test/evaluate the model. We can do this quite easily using another builtin method from keras.\n","\n","The *verbose* argument is defined from the keras documentation as:\n","\"verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\"\n","(https://keras.io/models/sequential/)"]},{"cell_type":"code","metadata":{"id":"WqI0FEO54XN1","colab_type":"code","outputId":"b4c13411-a7cb-42f0-9c60-8c2bab45366e","executionInfo":{"status":"ok","timestamp":1590922982347,"user_tz":-120,"elapsed":39963,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=1) \n","\n","print('Test accuracy:', test_acc)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"313/313 [==============================] - 0s 798us/step - loss: 0.3408 - accuracy: 0.8817\nTest accuracy: 0.8816999793052673\n"}]},{"cell_type":"markdown","metadata":{"id":"nb4_EtfK5DuW","colab_type":"text"},"source":["You'll likely notice that the accuracy here is lower than when training the model. This difference is reffered to as **overfitting**.\n","\n","And now we have a trained model that's ready to use to predict some values!"]},{"cell_type":"markdown","metadata":{"id":"Pv0XpgwJ7GlW","colab_type":"text"},"source":["## Making Predictions\n","To make predictions we simply need to pass an array of data in the form we've specified in the input layer to ```.predict()``` method."]},{"cell_type":"code","metadata":{"id":"BMAkNWii7Ufj","colab_type":"code","colab":{}},"source":["predictions = model.predict(test_images)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LmRgxuEc7Xjc","colab_type":"text"},"source":["This method returns to us an array of predictions for each image we passed it. Let's have a look at the predictions for image 1."]},{"cell_type":"code","metadata":{"id":"4y2eQtCr7fnd","colab_type":"code","outputId":"010d000d-337b-4992-dd3f-c4beefa9caa4","executionInfo":{"status":"ok","timestamp":1590922982677,"user_tz":-120,"elapsed":40273,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["predictions[0]"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([3.0851302e-09, 3.3350117e-10, 1.1074089e-10, 6.9785839e-12,\n       4.6257234e-09, 3.3317856e-04, 1.1814582e-09, 3.5732012e-02,\n       9.5847481e-09, 9.6393484e-01], dtype=float32)"},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"eiRNg9Yr7lCt","colab_type":"text"},"source":["If we wan't to get the value with the highest score we can use a useful function from numpy called ```argmax()```. This simply returns the index of the maximium value from a numpy array. "]},{"cell_type":"code","metadata":{"id":"NaagMfi671ci","colab_type":"code","outputId":"650e11a7-5572-4a1c-91bb-c1f1c26ace6a","executionInfo":{"status":"ok","timestamp":1590922982678,"user_tz":-120,"elapsed":40262,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.argmax(predictions[0])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":"9"},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"aWY4SKYm8h93","colab_type":"text"},"source":["And we can check if this is correct by looking at the value of the cooresponding test label."]},{"cell_type":"code","metadata":{"id":"xVNepduo8nEy","colab_type":"code","outputId":"a270d721-40da-4de4-cdd9-ba79c590a33d","executionInfo":{"status":"ok","timestamp":1590922983051,"user_tz":-120,"elapsed":40624,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_labels[0]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":"9"},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"Y8I1EqJu8qRl","colab_type":"text"},"source":["## Verifying Predictions\n","I've written a small function here to help us verify predictions with some simple visuals."]},{"cell_type":"code","metadata":{"id":"-HJV4JF789aC","colab_type":"code","outputId":"31e051bc-afcb-45fa-8222-f1dc85cbfdfd","executionInfo":{"status":"ok","timestamp":1590923603518,"user_tz":-120,"elapsed":2548,"user":{"displayName":"Yair Bonastre","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgucoueHJYBt5Dz37rx5VyVbjjAbwPvFEYvjW6_=s64","userId":"05706845498661238300"}},"colab":{"base_uri":"https://localhost:8080/","height":320}},"source":["COLOR = 'white'\n","plt.rcParams['text.color'] = COLOR\n","plt.rcParams['axes.labelcolor'] = COLOR\n","\n","def predict(model, image, correct_label):\n","  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","  prediction = model.predict(np.array([image]))\n","  predicted_class = class_names[np.argmax(prediction)]\n","\n","  show_image(image, class_names[correct_label], predicted_class, np.max(prediction)*100)\n","\n","\n","def show_image(img, label, guess, accuracy):\n","  print(\"Expected: \" + label)\n","  plt.figure()\n","  plt.imshow(img, cmap=plt.cm.binary)\n","  plt.colorbar()\n","  plt.grid(False)\n","  plt.show()\n","  print(f'Guess: {guess} - Accuracy: {accuracy:.1f}%')\n","\n","\n","def get_number():\n","  while True:\n","    num = input(\"Pick a number: \")\n","    if num.isdigit():\n","      num = int(num)\n","      if 0 <= num <= 1000:\n","        return int(num)\n","    else:\n","      print(\"Try again...\")\n","\n","num = get_number()\n","image = test_images[num]\n","label = test_labels[num]\n","predict(model, image, label)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"Try again...\nTry again...\nTry again...\nExpected: Coat\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"252.317344pt\" version=\"1.1\" viewBox=\"0 0 302.080125 252.317344\" width=\"302.080125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 252.317344 \nL 302.080125 252.317344 \nL 302.080125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 228.439219 \nL 244.365 228.439219 \nL 244.365 10.999219 \nL 26.925 10.999219 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p8d6a7fd07c)\">\n    <image height=\"218\" id=\"imagee0844635f2\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-10.439219\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"meb151f0f7a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#meb151f0f7a\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(27.626607 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#meb151f0f7a\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(66.455179 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#meb151f0f7a\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(102.1025 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#meb151f0f7a\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#meb151f0f7a\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(179.759643 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#meb151f0f7a\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 243.037656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m4e3865e819\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4e3865e819\" y=\"14.882076\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 18.681295)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4e3865e819\" y=\"53.710647\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 57.509866)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4e3865e819\" y=\"92.539219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 96.338437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4e3865e819\" y=\"131.36779\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 135.167009)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4e3865e819\" y=\"170.196362\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 173.99558)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m4e3865e819\" y=\"209.024933\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 212.824152)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 228.439219 \nL 26.925 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 228.439219 \nL 244.365 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 228.439219 \nL 244.365 228.439219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 10.999219 \nL 244.365 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pd9bc502239)\" d=\"M 261.105 228.439219 \nL 261.105 227.589844 \nL 261.105 11.848594 \nL 261.105 10.999219 \nL 271.977 10.999219 \nL 271.977 11.848594 \nL 271.977 227.589844 \nL 271.977 228.439219 \nz\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\n   </g>\n   <image height=\"217\" id=\"image9319bac49b\" transform=\"scale(1 -1)translate(0 -217)\" width=\"11\" x=\"261\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAAsAAADZCAYAAAD2WsoCAAAABHNCSVQICAgIfAhkiAAAAIZJREFUaIHt0DEKwDAMBEEZ8v8ny2lVmoOAs6zqLXSzunvX4T17H7dfxt19wxuXxGrMGK+BH6hGHOM18APVmDF+oBpxjNfAD1QjjvEa+IFqxDFeAz9QjRnjB6oRx3gN/EA14hivgR+oRhzjNfAD1YhjvAZ+oBozxg9UI47xGviBP9RYVXVcv7byin7iZ0+DAAAAAElFTkSuQmCC\" y=\"-11\"/>\n   <g id=\"matplotlib.axis_3\"/>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <defs>\n       <path d=\"M 0 0 \nL 3.5 0 \n\" id=\"m965c979662\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#m965c979662\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(278.977 232.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#m965c979662\" y=\"184.951219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.2 -->\n      <g transform=\"translate(278.977 188.750437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#m965c979662\" y=\"141.463219\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(278.977 145.262437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#m965c979662\" y=\"97.975219\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(278.977 101.774437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#m965c979662\" y=\"54.487219\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(278.977 58.286437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.977\" xlink:href=\"#m965c979662\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 1.0 -->\n      <g transform=\"translate(278.977 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 261.105 228.439219 \nL 261.105 227.589844 \nL 261.105 11.848594 \nL 261.105 10.999219 \nL 271.977 10.999219 \nL 271.977 11.848594 \nL 271.977 227.589844 \nL 271.977 228.439219 \nz\n\" style=\"fill:none;stroke:#000000;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p8d6a7fd07c\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"10.999219\"/>\n  </clipPath>\n  <clipPath id=\"pd9bc502239\">\n   <rect height=\"217.44\" width=\"10.872\" x=\"261.105\" y=\"10.999219\"/>\n  </clipPath>\n </defs>\n</svg>\n","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":"Guess: Coat - Accuracy: 91.2%\n"}]},{"cell_type":"markdown","metadata":{"id":"1HRzP5hCAijM","colab_type":"text"},"source":["And that's pretty much it for an introduction to neural networks!"]},{"cell_type":"markdown","metadata":{"id":"PmbcLZZ0lo_2","colab_type":"text"},"source":["## Sources\n","\n","1. Doshi, Sanket. Various Optimization Algorithms For Training Neural Network. Medium, Medium, 10 Mar. 2019, www.medium.com/@sdoshi579/optimizers-for-training-neural-network-59450d71caf6.\n","\n","2. Basic Classification: Classify Images of Clothing &nbsp;: &nbsp; TensorFlow Core. TensorFlow, www.tensorflow.org/tutorials/keras/classification.\n","\n","3. Gradient Descent. Gradient Descent - ML Glossary Documentation, www.ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html.\n","\n","4. Chollet Francois. Deep Learning with Python. Manning Publications Co., 2018.\n","\n","5. Keras: The Python Deep Learning Library. Home - Keras Documentation, www.keras.io/."]}],"metadata":{"colab":{"name":"3 - Deep Learning - Neural Networks - Classifier (Fashion MNIST).ipynb","provenance":[{"file_id":"1m2cg3D1x3j5vrFc-Cu0gMvc48gWyCOuG","timestamp":1590494708687}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}